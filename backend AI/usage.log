2025-11-17 03:27:54,269 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 03:27:54,557 | Use pytorch device_name: cpu
2025-11-17 03:27:54,557 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 03:27:58,816 | [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3125
 * Running on http://192.168.2.62:3125
2025-11-17 03:27:58,816 | [33mPress CTRL+C to quit[0m
2025-11-17 03:27:58,818 |  * Restarting with stat
2025-11-17 03:28:13,832 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 03:28:13,931 | Use pytorch device_name: cpu
2025-11-17 03:28:13,931 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 03:28:17,586 |  * Debugger is active!
2025-11-17 03:28:17,589 |  * Debugger PIN: 136-249-302
2025-11-17 03:31:05,094 | 192.168.2.125 - - [17/Nov/2025 03:31:05] "[33mPOST /chat HTTP/1.1[0m" 404 -
2025-11-17 03:38:19,982 | HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 401 Unauthorized"
2025-11-17 03:38:20,003 | Ollama call error: Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 127, in chat
    response = ollama.chat(model=MODEL_NAME, messages=messages)
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 351, in chat
    return self._request(
           ~~~~~~~~~~~~~^
      ChatResponse,
      ^^^^^^^^^^^^^
    ...<12 lines>...
      stream=stream,
      ^^^^^^^^^^^^^^
    )
    ^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 189, in _request
    return cls(**self._request_raw(*args, **kwargs).json())
                 ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 133, in _request_raw
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: unauthorized (status code: 401)

2025-11-17 03:38:20,071 | user=HZjR9WyUAuCFsUjFIgLH | len=5 | time=1.14s
2025-11-17 03:38:20,072 | 192.168.2.125 - - [17/Nov/2025 03:38:20] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 03:43:26,672 |  * Detected change in 'D:\\Android\\Projects\\Nihongo\\backend AI\\nihongo.py', reloading
2025-11-17 03:43:31,055 |  * Restarting with stat
2025-11-17 03:44:17,410 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 03:44:17,555 | Use pytorch device_name: cpu
2025-11-17 03:44:17,555 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 03:44:22,324 | [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3125
 * Running on http://192.168.2.62:3125
2025-11-17 03:44:22,324 | [33mPress CTRL+C to quit[0m
2025-11-17 03:44:22,327 |  * Restarting with stat
2025-11-17 03:44:40,583 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 03:44:40,704 | Use pytorch device_name: cpu
2025-11-17 03:44:40,704 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 03:44:45,028 |  * Debugger is active!
2025-11-17 03:44:45,044 |  * Debugger PIN: 136-249-302
2025-11-17 03:45:39,563 | Ollama call error: Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 134, in chat
    response = ollama_client.chat(model=MODEL_NAME, messages=messages) # S\u1eeda \u1edf \u0111ây
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 351, in chat
    return self._request(
           ~~~~~~~~~~~~~^
      ChatResponse,
      ^^^^^^^^^^^^^
    ...<12 lines>...
      stream=stream,
      ^^^^^^^^^^^^^^
    )
    ^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 189, in _request
    return cls(**self._request_raw(*args, **kwargs).json())
                 ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 135, in _request_raw
    raise ConnectionError(CONNECTION_ERROR_MESSAGE) from None
ConnectionError: Failed to connect to Ollama. Please check that Ollama is downloaded, running and accessible. https://ollama.com/download

2025-11-17 03:45:39,627 | user=HZjR9WyUAuCFsUjFIgLH | len=5 | time=0.23s
2025-11-17 03:45:39,629 | 192.168.2.125 - - [17/Nov/2025 03:45:39] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 03:45:58,821 |  * Detected change in 'D:\\Android\\Projects\\Nihongo\\backend AI\\nihongo.py', reloading
2025-11-17 03:46:01,109 |  * Restarting with stat
2025-11-17 03:46:19,376 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 03:46:19,548 | Use pytorch device_name: cpu
2025-11-17 03:46:19,548 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 03:46:23,586 |  * Debugger is active!
2025-11-17 03:46:23,592 |  * Debugger PIN: 136-249-302
2025-11-17 03:47:38,214 |  * Detected change in 'D:\\Android\\Projects\\Nihongo\\backend AI\\nihongo.py', reloading
2025-11-17 03:47:40,404 |  * Restarting with stat
2025-11-17 03:47:56,228 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 03:47:56,331 | Use pytorch device_name: cpu
2025-11-17 03:47:56,331 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 03:48:00,514 |  * Debugger is active!
2025-11-17 03:48:00,518 |  * Debugger PIN: 136-249-302
2025-11-17 03:48:27,766 |  * Detected change in 'D:\\Android\\Projects\\Nihongo\\backend AI\\nihongo.py', reloading
2025-11-17 03:48:29,708 |  * Restarting with stat
2025-11-17 03:49:05,670 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 03:49:05,836 | Use pytorch device_name: cpu
2025-11-17 03:49:05,836 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 03:49:09,995 | [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3125
 * Running on http://192.168.2.62:3125
2025-11-17 03:49:09,995 | [33mPress CTRL+C to quit[0m
2025-11-17 03:49:09,998 |  * Restarting with stat
2025-11-17 03:49:26,124 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 03:49:26,233 | Use pytorch device_name: cpu
2025-11-17 03:49:26,233 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 03:49:30,501 |  * Debugger is active!
2025-11-17 03:49:30,507 |  * Debugger PIN: 136-249-302
2025-11-17 03:49:50,675 |  * Detected change in 'D:\\Android\\Projects\\Nihongo\\backend AI\\nihongo.py', reloading
2025-11-17 03:49:52,342 |  * Restarting with stat
2025-11-17 03:50:32,268 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 03:50:32,383 | Use pytorch device_name: cpu
2025-11-17 03:50:32,383 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 03:50:36,179 | [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3125
 * Running on http://192.168.2.62:3125
2025-11-17 03:50:36,179 | [33mPress CTRL+C to quit[0m
2025-11-17 03:50:36,180 |  * Restarting with stat
2025-11-17 03:50:54,667 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 03:50:54,801 | Use pytorch device_name: cpu
2025-11-17 03:50:54,801 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 03:50:58,948 |  * Debugger is active!
2025-11-17 03:50:58,952 |  * Debugger PIN: 136-249-302
2025-11-17 03:52:56,617 | HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 401 Unauthorized"
2025-11-17 03:52:56,620 | Ollama call error: Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 127, in chat
    response = ollama.chat(model=MODEL_NAME, messages=messages)
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 351, in chat
    return self._request(
           ~~~~~~~~~~~~~^
      ChatResponse,
      ^^^^^^^^^^^^^
    ...<12 lines>...
      stream=stream,
      ^^^^^^^^^^^^^^
    )
    ^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 189, in _request
    return cls(**self._request_raw(*args, **kwargs).json())
                 ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 133, in _request_raw
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: unauthorized (status code: 401)

2025-11-17 03:52:56,691 | user=HZjR9WyUAuCFsUjFIgLH | len=5 | time=1.27s
2025-11-17 03:52:56,692 | 192.168.2.125 - - [17/Nov/2025 03:52:56] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 03:55:24,404 |  * Detected change in 'D:\\Android\\Projects\\Nihongo\\backend AI\\nihongo.py', reloading
2025-11-17 03:55:26,463 |  * Restarting with stat
2025-11-17 03:55:43,294 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 03:55:43,395 | Use pytorch device_name: cpu
2025-11-17 03:55:43,395 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 03:55:47,653 |  * Debugger is active!
2025-11-17 03:55:47,656 |  * Debugger PIN: 136-249-302
2025-11-17 03:57:50,079 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 03:57:50,195 | Use pytorch device_name: cpu
2025-11-17 03:57:50,195 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 03:57:54,163 | [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3125
 * Running on http://192.168.2.62:3125
2025-11-17 03:57:54,163 | [33mPress CTRL+C to quit[0m
2025-11-17 03:57:54,165 |  * Restarting with stat
2025-11-17 03:58:11,884 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 03:58:12,060 | Use pytorch device_name: cpu
2025-11-17 03:58:12,060 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 03:58:16,355 |  * Debugger is active!
2025-11-17 03:58:16,367 |  * Debugger PIN: 136-249-302
2025-11-17 04:02:09,051 |  * Detected change in 'D:\\Android\\Projects\\Nihongo\\backend AI\\nihongo.py', reloading
2025-11-17 04:02:11,325 |  * Restarting with stat
2025-11-17 04:02:47,144 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 04:02:47,256 | Use pytorch device_name: cpu
2025-11-17 04:02:47,257 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 04:02:53,316 | HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2025-11-17 04:02:53,344 | [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3125
 * Running on http://192.168.2.62:3125
2025-11-17 04:02:53,344 | [33mPress CTRL+C to quit[0m
2025-11-17 04:02:53,346 |  * Restarting with stat
2025-11-17 04:03:09,088 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 04:03:09,209 | Use pytorch device_name: cpu
2025-11-17 04:03:09,211 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 04:03:15,722 | HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2025-11-17 04:03:15,735 |  * Debugger is active!
2025-11-17 04:03:15,740 |  * Debugger PIN: 136-249-302
2025-11-17 04:03:16,394 | HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 401 Unauthorized"
2025-11-17 04:03:16,396 | Ollama call error: Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 136, in chat
    response = ollama_client.chat(model=MODEL_NAME, messages=messages)
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 351, in chat
    return self._request(
           ~~~~~~~~~~~~~^
      ChatResponse,
      ^^^^^^^^^^^^^
    ...<12 lines>...
      stream=stream,
      ^^^^^^^^^^^^^^
    )
    ^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 189, in _request
    return cls(**self._request_raw(*args, **kwargs).json())
                 ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 133, in _request_raw
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: unauthorized (status code: 401)

2025-11-17 04:03:16,456 | user=HZjR9WyUAuCFsUjFIgLH | len=10 | time=0.70s
2025-11-17 04:03:16,457 | 192.168.2.125 - - [17/Nov/2025 04:03:16] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 04:03:27,183 | HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 401 Unauthorized"
2025-11-17 04:03:27,184 | Ollama call error: Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 136, in chat
    response = ollama_client.chat(model=MODEL_NAME, messages=messages)
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 351, in chat
    return self._request(
           ~~~~~~~~~~~~~^
      ChatResponse,
      ^^^^^^^^^^^^^
    ...<12 lines>...
      stream=stream,
      ^^^^^^^^^^^^^^
    )
    ^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 189, in _request
    return cls(**self._request_raw(*args, **kwargs).json())
                 ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 133, in _request_raw
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: unauthorized (status code: 401)

2025-11-17 04:03:27,199 | user=HZjR9WyUAuCFsUjFIgLH | len=5 | time=2.32s
2025-11-17 04:03:27,199 | 192.168.2.125 - - [17/Nov/2025 04:03:27] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 04:09:28,460 |  * Detected change in 'D:\\Android\\Projects\\Nihongo\\backend AI\\nihongo.py', reloading
2025-11-17 04:09:31,111 |  * Restarting with stat
2025-11-17 04:09:51,210 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 04:09:51,351 | Use pytorch device_name: cpu
2025-11-17 04:09:51,351 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 04:09:55,734 |  * Debugger is active!
2025-11-17 04:09:55,742 |  * Debugger PIN: 136-249-302
2025-11-17 04:10:29,018 |  * Detected change in 'D:\\Android\\Projects\\Nihongo\\backend AI\\nihongo.py', reloading
2025-11-17 04:10:30,574 |  * Restarting with stat
2025-11-17 04:11:03,603 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 04:11:03,716 | Use pytorch device_name: cpu
2025-11-17 04:11:03,716 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 04:11:08,131 | [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3125
 * Running on http://192.168.2.62:3125
2025-11-17 04:11:08,131 | [33mPress CTRL+C to quit[0m
2025-11-17 04:11:08,133 |  * Restarting with stat
2025-11-17 04:11:23,382 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 04:11:23,503 | Use pytorch device_name: cpu
2025-11-17 04:11:23,503 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 04:11:27,639 |  * Debugger is active!
2025-11-17 04:11:27,643 |  * Debugger PIN: 136-249-302
2025-11-17 04:13:18,718 |  * Detected change in 'D:\\Android\\Projects\\Nihongo\\backend AI\\nihongo.py', reloading
2025-11-17 04:13:20,533 |  * Restarting with stat
2025-11-17 04:13:35,094 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 04:13:35,234 | Use pytorch device_name: cpu
2025-11-17 04:13:35,234 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 04:13:41,405 | HTTP Request: GET http://localhost:11434/api/tags "HTTP/1.1 200 OK"
2025-11-17 04:13:41,416 |  * Debugger is active!
2025-11-17 04:13:41,420 |  * Debugger PIN: 136-249-302
2025-11-17 04:14:14,204 | HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 401 Unauthorized"
2025-11-17 04:14:14,207 | Ollama call error: Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 136, in chat
    response = ollama_client.chat(model=MODEL_NAME, messages=messages)
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 351, in chat
    return self._request(
           ~~~~~~~~~~~~~^
      ChatResponse,
      ^^^^^^^^^^^^^
    ...<12 lines>...
      stream=stream,
      ^^^^^^^^^^^^^^
    )
    ^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 189, in _request
    return cls(**self._request_raw(*args, **kwargs).json())
                 ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 133, in _request_raw
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: unauthorized (status code: 401)

2025-11-17 04:14:14,259 | user=HZjR9WyUAuCFsUjFIgLH | len=5 | time=2.55s
2025-11-17 04:14:14,261 | 192.168.2.125 - - [17/Nov/2025 04:14:14] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 04:19:58,541 |  * Detected change in 'D:\\Android\\Projects\\Nihongo\\backend AI\\nihongo.py', reloading
2025-11-17 04:20:02,675 |  * Restarting with stat
2025-11-17 04:20:29,186 | INFO | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 04:20:29,561 | INFO | Use pytorch device_name: cpu
2025-11-17 04:20:29,561 | INFO | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 04:20:33,965 | WARNING |  * Debugger is active!
2025-11-17 04:20:33,969 | INFO |  * Debugger PIN: 136-249-302
2025-11-17 04:21:02,193 | ERROR | LLM generation error: Traceback (most recent call last):
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connection.py", line 198, in _new_conn
    sock = connection.create_connection(
        (self._dns_host, self.port),
    ...<2 lines>...
        socket_options=self.socket_options,
    )
  File "D:\Python Jupiter\Lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
               ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\socket.py", line 977, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connectionpool.py", line 488, in _make_request
    raise new_e
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connectionpool.py", line 464, in _make_request
    self._validate_conn(conn)
    ~~~~~~~~~~~~~~~~~~~^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connectionpool.py", line 1093, in _validate_conn
    conn.connect()
    ~~~~~~~~~~~~^^
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connection.py", line 704, in connect
    self.sock = sock = self._new_conn()
                       ~~~~~~~~~~~~~~^^
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connection.py", line 205, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x000001E2DD769BD0>: Failed to resolve 'api.ollama.ai' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\Python Jupiter\Lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "D:\Python Jupiter\Lib\site-packages\urllib3\util\retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.ollama.ai', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001E2DD769BD0>: Failed to resolve 'api.ollama.ai' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 93, in call_ollama_cloud
    r = requests.post(OLLAMA_CLOUD_URL, headers=headers, json=payload, timeout=HTTP_TIMEOUT)
  File "D:\Python Jupiter\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "D:\Python Jupiter\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Python Jupiter\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\Python Jupiter\Lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='api.ollama.ai', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001E2DD769BD0>: Failed to resolve 'api.ollama.ai' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 235, in chat
    reply_text = generate_reply_from_llm(messages, prefer="auto", temperature=0.3)
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 166, in generate_reply_from_llm
    return call_ollama_cloud(messages, temperature=temperature)
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 95, in call_ollama_cloud
    raise RuntimeError(f"Network error calling Ollama Cloud: {e}")
RuntimeError: Network error calling Ollama Cloud: HTTPSConnectionPool(host='api.ollama.ai', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001E2DD769BD0>: Failed to resolve 'api.ollama.ai' ([Errno 11001] getaddrinfo failed)"))

2025-11-17 04:21:02,261 | INFO | user=HZjR9WyUAuCFsUjFIgLH | len=5 | time=0.50s
2025-11-17 04:21:02,262 | INFO | 192.168.2.125 - - [17/Nov/2025 04:21:02] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 04:22:32,178 | INFO |  * Detected change in 'D:\\Android\\Projects\\Nihongo\\backend AI\\nihongo.py', reloading
2025-11-17 04:22:34,487 |  * Restarting with stat
2025-11-17 04:22:53,425 | INFO | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 04:22:53,542 | INFO | Use pytorch device_name: cpu
2025-11-17 04:22:53,542 | INFO | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 04:22:57,353 | WARNING |  * Debugger is active!
2025-11-17 04:22:57,358 | INFO |  * Debugger PIN: 136-249-302
2025-11-17 04:23:02,431 | INFO |  * Detected change in 'D:\\Android\\Projects\\Nihongo\\backend AI\\nihongo.py', reloading
2025-11-17 04:23:04,711 |  * Restarting with stat
2025-11-17 04:23:44,046 | INFO | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 04:23:44,155 | INFO | Use pytorch device_name: cpu
2025-11-17 04:23:44,155 | INFO | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 04:23:47,988 | INFO | [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3125
 * Running on http://192.168.2.62:3125
2025-11-17 04:23:47,988 | INFO | [33mPress CTRL+C to quit[0m
2025-11-17 04:23:47,989 | INFO |  * Restarting with stat
2025-11-17 04:24:06,238 | INFO | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 04:24:06,354 | INFO | Use pytorch device_name: cpu
2025-11-17 04:24:06,354 | INFO | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 04:24:10,242 | WARNING |  * Debugger is active!
2025-11-17 04:24:10,256 | INFO |  * Debugger PIN: 136-249-302
2025-11-17 04:24:10,420 | ERROR | LLM generation error: Traceback (most recent call last):
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connection.py", line 198, in _new_conn
    sock = connection.create_connection(
        (self._dns_host, self.port),
    ...<2 lines>...
        socket_options=self.socket_options,
    )
  File "D:\Python Jupiter\Lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
               ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\socket.py", line 977, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connectionpool.py", line 488, in _make_request
    raise new_e
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connectionpool.py", line 464, in _make_request
    self._validate_conn(conn)
    ~~~~~~~~~~~~~~~~~~~^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connectionpool.py", line 1093, in _validate_conn
    conn.connect()
    ~~~~~~~~~~~~^^
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connection.py", line 704, in connect
    self.sock = sock = self._new_conn()
                       ~~~~~~~~~~~~~~^^
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connection.py", line 205, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x00000178E3321D10>: Failed to resolve 'api.ollama.com' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\Python Jupiter\Lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "D:\Python Jupiter\Lib\site-packages\urllib3\util\retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.ollama.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x00000178E3321D10>: Failed to resolve 'api.ollama.com' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 93, in call_ollama_cloud
    r = requests.post(OLLAMA_CLOUD_URL, headers=headers, json=payload, timeout=HTTP_TIMEOUT)
  File "D:\Python Jupiter\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "D:\Python Jupiter\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Python Jupiter\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\Python Jupiter\Lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='api.ollama.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x00000178E3321D10>: Failed to resolve 'api.ollama.com' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 235, in chat
    reply_text = generate_reply_from_llm(messages, prefer="auto", temperature=0.3)
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 166, in generate_reply_from_llm
    return call_ollama_cloud(messages, temperature=temperature)
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 95, in call_ollama_cloud
    raise RuntimeError(f"Network error calling Ollama Cloud: {e}")
RuntimeError: Network error calling Ollama Cloud: HTTPSConnectionPool(host='api.ollama.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x00000178E3321D10>: Failed to resolve 'api.ollama.com' ([Errno 11001] getaddrinfo failed)"))

2025-11-17 04:24:10,462 | INFO | user=HZjR9WyUAuCFsUjFIgLH | len=5 | time=0.19s
2025-11-17 04:24:10,463 | INFO | 192.168.2.125 - - [17/Nov/2025 04:24:10] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 04:24:17,162 | ERROR | LLM generation error: Traceback (most recent call last):
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connection.py", line 198, in _new_conn
    sock = connection.create_connection(
        (self._dns_host, self.port),
    ...<2 lines>...
        socket_options=self.socket_options,
    )
  File "D:\Python Jupiter\Lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
               ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\socket.py", line 977, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connectionpool.py", line 488, in _make_request
    raise new_e
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connectionpool.py", line 464, in _make_request
    self._validate_conn(conn)
    ~~~~~~~~~~~~~~~~~~~^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connectionpool.py", line 1093, in _validate_conn
    conn.connect()
    ~~~~~~~~~~~~^^
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connection.py", line 704, in connect
    self.sock = sock = self._new_conn()
                       ~~~~~~~~~~~~~~^^
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connection.py", line 205, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x00000178E3322D50>: Failed to resolve 'api.ollama.com' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\Python Jupiter\Lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "D:\Python Jupiter\Lib\site-packages\urllib3\util\retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.ollama.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x00000178E3322D50>: Failed to resolve 'api.ollama.com' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 93, in call_ollama_cloud
    r = requests.post(OLLAMA_CLOUD_URL, headers=headers, json=payload, timeout=HTTP_TIMEOUT)
  File "D:\Python Jupiter\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "D:\Python Jupiter\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Python Jupiter\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\Python Jupiter\Lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='api.ollama.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x00000178E3322D50>: Failed to resolve 'api.ollama.com' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 235, in chat
    reply_text = generate_reply_from_llm(messages, prefer="auto", temperature=0.3)
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 166, in generate_reply_from_llm
    return call_ollama_cloud(messages, temperature=temperature)
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 95, in call_ollama_cloud
    raise RuntimeError(f"Network error calling Ollama Cloud: {e}")
RuntimeError: Network error calling Ollama Cloud: HTTPSConnectionPool(host='api.ollama.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x00000178E3322D50>: Failed to resolve 'api.ollama.com' ([Errno 11001] getaddrinfo failed)"))

2025-11-17 04:24:17,187 | INFO | user=HZjR9WyUAuCFsUjFIgLH | len=5 | time=0.07s
2025-11-17 04:24:17,188 | INFO | 192.168.2.125 - - [17/Nov/2025 04:24:17] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 04:24:22,229 | ERROR | LLM generation error: Traceback (most recent call last):
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connection.py", line 198, in _new_conn
    sock = connection.create_connection(
        (self._dns_host, self.port),
    ...<2 lines>...
        socket_options=self.socket_options,
    )
  File "D:\Python Jupiter\Lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
               ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\socket.py", line 977, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connectionpool.py", line 488, in _make_request
    raise new_e
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connectionpool.py", line 464, in _make_request
    self._validate_conn(conn)
    ~~~~~~~~~~~~~~~~~~~^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connectionpool.py", line 1093, in _validate_conn
    conn.connect()
    ~~~~~~~~~~~~^^
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connection.py", line 704, in connect
    self.sock = sock = self._new_conn()
                       ~~~~~~~~~~~~~~^^
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connection.py", line 205, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x00000178E3322C10>: Failed to resolve 'api.ollama.com' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\Python Jupiter\Lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "D:\Python Jupiter\Lib\site-packages\urllib3\util\retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.ollama.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x00000178E3322C10>: Failed to resolve 'api.ollama.com' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 93, in call_ollama_cloud
    r = requests.post(OLLAMA_CLOUD_URL, headers=headers, json=payload, timeout=HTTP_TIMEOUT)
  File "D:\Python Jupiter\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "D:\Python Jupiter\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Python Jupiter\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\Python Jupiter\Lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='api.ollama.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x00000178E3322C10>: Failed to resolve 'api.ollama.com' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 235, in chat
    reply_text = generate_reply_from_llm(messages, prefer="auto", temperature=0.3)
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 166, in generate_reply_from_llm
    return call_ollama_cloud(messages, temperature=temperature)
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 95, in call_ollama_cloud
    raise RuntimeError(f"Network error calling Ollama Cloud: {e}")
RuntimeError: Network error calling Ollama Cloud: HTTPSConnectionPool(host='api.ollama.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x00000178E3322C10>: Failed to resolve 'api.ollama.com' ([Errno 11001] getaddrinfo failed)"))

2025-11-17 04:24:22,250 | INFO | user=HZjR9WyUAuCFsUjFIgLH | len=3 | time=0.05s
2025-11-17 04:24:22,250 | INFO | 192.168.2.125 - - [17/Nov/2025 04:24:22] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 08:12:47,147 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 08:12:47,437 | Use pytorch device_name: cpu
2025-11-17 08:12:47,437 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 08:12:55,053 | [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3125
 * Running on http://10.242.233.83:3125
2025-11-17 08:12:55,053 | [33mPress CTRL+C to quit[0m
2025-11-17 08:12:55,056 |  * Restarting with stat
2025-11-17 08:13:12,759 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 08:13:12,880 | Use pytorch device_name: cpu
2025-11-17 08:13:12,881 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 08:13:18,424 |  * Debugger is active!
2025-11-17 08:13:18,429 |  * Debugger PIN: 136-249-302
2025-11-17 08:15:25,338 | HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 401 Unauthorized"
2025-11-17 08:15:25,341 | Ollama call error: Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 125, in chat
    response = ollama.chat(model=MODEL_NAME, messages=messages)
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 351, in chat
    return self._request(
           ~~~~~~~~~~~~~^
      ChatResponse,
      ^^^^^^^^^^^^^
    ...<12 lines>...
      stream=stream,
      ^^^^^^^^^^^^^^
    )
    ^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 189, in _request
    return cls(**self._request_raw(*args, **kwargs).json())
                 ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 133, in _request_raw
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: unauthorized (status code: 401)

2025-11-17 08:15:25,407 | user=FRjnep1OzM8mpMDiIiyu | len=193 | time=1.26s
2025-11-17 08:15:25,408 | 10.242.233.111 - - [17/Nov/2025 08:15:25] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 08:15:28,200 | HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 401 Unauthorized"
2025-11-17 08:15:28,201 | Ollama call error: Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 125, in chat
    response = ollama.chat(model=MODEL_NAME, messages=messages)
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 351, in chat
    return self._request(
           ~~~~~~~~~~~~~^
      ChatResponse,
      ^^^^^^^^^^^^^
    ...<12 lines>...
      stream=stream,
      ^^^^^^^^^^^^^^
    )
    ^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 189, in _request
    return cls(**self._request_raw(*args, **kwargs).json())
                 ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 133, in _request_raw
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: unauthorized (status code: 401)

2025-11-17 08:15:28,220 | user=Lx0v6alhIHxtyT0omFDh | len=193 | time=0.61s
2025-11-17 08:15:28,220 | 10.242.233.111 - - [17/Nov/2025 08:15:28] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 08:15:29,740 | HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 401 Unauthorized"
2025-11-17 08:15:29,741 | Ollama call error: Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 125, in chat
    response = ollama.chat(model=MODEL_NAME, messages=messages)
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 351, in chat
    return self._request(
           ~~~~~~~~~~~~~^
      ChatResponse,
      ^^^^^^^^^^^^^
    ...<12 lines>...
      stream=stream,
      ^^^^^^^^^^^^^^
    )
    ^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 189, in _request
    return cls(**self._request_raw(*args, **kwargs).json())
                 ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 133, in _request_raw
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: unauthorized (status code: 401)

2025-11-17 08:15:29,761 | user=UoPAelOGnpLkK3uk4Kb1 | len=193 | time=0.37s
2025-11-17 08:15:29,762 | 10.242.233.111 - - [17/Nov/2025 08:15:29] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 08:15:31,400 | HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 401 Unauthorized"
2025-11-17 08:15:31,407 | Ollama call error: Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 125, in chat
    response = ollama.chat(model=MODEL_NAME, messages=messages)
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 351, in chat
    return self._request(
           ~~~~~~~~~~~~~^
      ChatResponse,
      ^^^^^^^^^^^^^
    ...<12 lines>...
      stream=stream,
      ^^^^^^^^^^^^^^
    )
    ^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 189, in _request
    return cls(**self._request_raw(*args, **kwargs).json())
                 ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 133, in _request_raw
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: unauthorized (status code: 401)

2025-11-17 08:15:31,447 | user=VFVKIRlqixVhTsGE7lCh | len=193 | time=0.40s
2025-11-17 08:15:31,447 | 10.242.233.111 - - [17/Nov/2025 08:15:31] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 08:15:32,967 | HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 401 Unauthorized"
2025-11-17 08:15:32,969 | Ollama call error: Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 125, in chat
    response = ollama.chat(model=MODEL_NAME, messages=messages)
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 351, in chat
    return self._request(
           ~~~~~~~~~~~~~^
      ChatResponse,
      ^^^^^^^^^^^^^
    ...<12 lines>...
      stream=stream,
      ^^^^^^^^^^^^^^
    )
    ^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 189, in _request
    return cls(**self._request_raw(*args, **kwargs).json())
                 ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 133, in _request_raw
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: unauthorized (status code: 401)

2025-11-17 08:15:32,995 | user=k4IrYKtjRrB73qPy8CPG | len=193 | time=0.40s
2025-11-17 08:15:32,996 | 10.242.233.111 - - [17/Nov/2025 08:15:32] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 08:15:52,799 | HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 401 Unauthorized"
2025-11-17 08:15:52,800 | Ollama call error: Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 125, in chat
    response = ollama.chat(model=MODEL_NAME, messages=messages)
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 351, in chat
    return self._request(
           ~~~~~~~~~~~~~^
      ChatResponse,
      ^^^^^^^^^^^^^
    ...<12 lines>...
      stream=stream,
      ^^^^^^^^^^^^^^
    )
    ^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 189, in _request
    return cls(**self._request_raw(*args, **kwargs).json())
                 ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 133, in _request_raw
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: unauthorized (status code: 401)

2025-11-17 08:15:52,843 | user=HZjR9WyUAuCFsUjFIgLH | len=5 | time=0.52s
2025-11-17 08:15:52,847 | 10.242.233.111 - - [17/Nov/2025 08:15:52] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 08:17:25,484 | HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 401 Unauthorized"
2025-11-17 08:17:25,485 | Ollama call error: Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 125, in chat
    response = ollama.chat(model=MODEL_NAME, messages=messages)
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 351, in chat
    return self._request(
           ~~~~~~~~~~~~~^
      ChatResponse,
      ^^^^^^^^^^^^^
    ...<12 lines>...
      stream=stream,
      ^^^^^^^^^^^^^^
    )
    ^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 189, in _request
    return cls(**self._request_raw(*args, **kwargs).json())
                 ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 133, in _request_raw
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: unauthorized (status code: 401)

2025-11-17 08:17:25,501 | user=HZjR9WyUAuCFsUjFIgLH | len=2 | time=0.58s
2025-11-17 08:17:25,502 | 10.242.233.111 - - [17/Nov/2025 08:17:25] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 08:17:57,800 | HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 401 Unauthorized"
2025-11-17 08:17:57,801 | Ollama call error: Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 125, in chat
    response = ollama.chat(model=MODEL_NAME, messages=messages)
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 351, in chat
    return self._request(
           ~~~~~~~~~~~~~^
      ChatResponse,
      ^^^^^^^^^^^^^
    ...<12 lines>...
      stream=stream,
      ^^^^^^^^^^^^^^
    )
    ^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 189, in _request
    return cls(**self._request_raw(*args, **kwargs).json())
                 ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 133, in _request_raw
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: unauthorized (status code: 401)

2025-11-17 08:17:57,814 | user=HZjR9WyUAuCFsUjFIgLH | len=2 | time=0.65s
2025-11-17 08:17:57,815 | 10.242.233.111 - - [17/Nov/2025 08:17:57] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 08:19:50,530 | HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 401 Unauthorized"
2025-11-17 08:19:50,531 | Ollama call error: Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 125, in chat
    response = ollama.chat(model=MODEL_NAME, messages=messages)
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 351, in chat
    return self._request(
           ~~~~~~~~~~~~~^
      ChatResponse,
      ^^^^^^^^^^^^^
    ...<12 lines>...
      stream=stream,
      ^^^^^^^^^^^^^^
    )
    ^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 189, in _request
    return cls(**self._request_raw(*args, **kwargs).json())
                 ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 133, in _request_raw
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: unauthorized (status code: 401)

2025-11-17 08:19:50,546 | user=HZjR9WyUAuCFsUjFIgLH | len=5 | time=1.28s
2025-11-17 08:19:50,547 | 10.242.233.111 - - [17/Nov/2025 08:19:50] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 08:22:30,990 |  * Detected change in 'D:\\Android\\Projects\\Nihongo\\backend AI\\nihongo.py', reloading
2025-11-17 08:22:33,045 |  * Restarting with stat
2025-11-17 08:22:53,737 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 08:22:53,881 | Use pytorch device_name: cpu
2025-11-17 08:22:53,881 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 08:23:01,255 |  * Debugger is active!
2025-11-17 08:23:01,259 |  * Debugger PIN: 136-249-302
2025-11-17 08:23:13,393 |  * Detected change in 'D:\\Android\\Projects\\Nihongo\\backend AI\\nihongo.py', reloading
2025-11-17 08:23:15,151 |  * Restarting with stat
2025-11-17 08:23:30,583 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 08:23:30,750 | Use pytorch device_name: cpu
2025-11-17 08:23:30,750 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 08:23:36,230 |  * Debugger is active!
2025-11-17 08:23:36,238 |  * Debugger PIN: 136-249-302
2025-11-17 08:24:07,762 | HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 401 Unauthorized"
2025-11-17 08:24:07,775 | Ollama call error: Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 126, in chat
    response = ollama.chat(model=MODEL_NAME, messages=messages)
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 351, in chat
    return self._request(
           ~~~~~~~~~~~~~^
      ChatResponse,
      ^^^^^^^^^^^^^
    ...<12 lines>...
      stream=stream,
      ^^^^^^^^^^^^^^
    )
    ^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 189, in _request
    return cls(**self._request_raw(*args, **kwargs).json())
                 ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\ollama\_client.py", line 133, in _request_raw
    raise ResponseError(e.response.text, e.response.status_code) from None
ollama._types.ResponseError: unauthorized (status code: 401)

2025-11-17 08:24:07,820 | user=HZjR9WyUAuCFsUjFIgLH | len=5 | time=1.42s
2025-11-17 08:24:07,821 | 10.242.233.111 - - [17/Nov/2025 08:24:07] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 08:41:42,579 |  * Detected change in 'D:\\Android\\Projects\\Nihongo\\backend AI\\nihongo.py', reloading
2025-11-17 08:41:44,321 |  * Restarting with stat
2025-11-17 09:07:12,652 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 09:07:12,823 | Use pytorch device_name: cpu
2025-11-17 09:07:12,823 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 09:07:20,524 | [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3125
 * Running on http://10.242.233.83:3125
2025-11-17 09:07:20,524 | [33mPress CTRL+C to quit[0m
2025-11-17 09:07:20,526 |  * Restarting with stat
2025-11-17 09:07:34,247 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 09:07:34,341 | Use pytorch device_name: cpu
2025-11-17 09:07:34,341 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 09:07:40,639 |  * Debugger is active!
2025-11-17 09:07:40,643 |  * Debugger PIN: 136-249-302
2025-11-17 09:08:55,706 | Ollama error: Traceback (most recent call last):
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connection.py", line 198, in _new_conn
    sock = connection.create_connection(
        (self._dns_host, self.port),
    ...<2 lines>...
        socket_options=self.socket_options,
    )
  File "D:\Python Jupiter\Lib\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
               ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\socket.py", line 977, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno 11001] getaddrinfo failed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
        conn,
    ...<10 lines>...
        **response_kw,
    )
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connectionpool.py", line 488, in _make_request
    raise new_e
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connectionpool.py", line 464, in _make_request
    self._validate_conn(conn)
    ~~~~~~~~~~~~~~~~~~~^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connectionpool.py", line 1093, in _validate_conn
    conn.connect()
    ~~~~~~~~~~~~^^
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connection.py", line 704, in connect
    self.sock = sock = self._new_conn()
                       ~~~~~~~~~~~~~~^^
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connection.py", line 205, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
urllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x000001FC3FFD39D0>: Failed to resolve 'api.ollama.com' ([Errno 11001] getaddrinfo failed)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\Python Jupiter\Lib\site-packages\requests\adapters.py", line 486, in send
    resp = conn.urlopen(
        method=request.method,
    ...<9 lines>...
        chunked=chunked,
    )
  File "D:\Python Jupiter\Lib\site-packages\urllib3\connectionpool.py", line 841, in urlopen
    retries = retries.increment(
        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
    )
  File "D:\Python Jupiter\Lib\site-packages\urllib3\util\retry.py", line 519, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.ollama.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001FC3FFD39D0>: Failed to resolve 'api.ollama.com' ([Errno 11001] getaddrinfo failed)"))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 172, in chat
    reply = call_ollama_cloud(MODEL_NAME, messages)
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 93, in call_ollama_cloud
    response = requests.post(OLLAMA_URL, headers=headers, json=payload)
  File "D:\Python Jupiter\Lib\site-packages\requests\api.py", line 115, in post
    return request("post", url, data=data, json=json, **kwargs)
  File "D:\Python Jupiter\Lib\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "D:\Python Jupiter\Lib\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "D:\Python Jupiter\Lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='api.ollama.com', port=443): Max retries exceeded with url: /v1/chat/completions (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x000001FC3FFD39D0>: Failed to resolve 'api.ollama.com' ([Errno 11001] getaddrinfo failed)"))

2025-11-17 09:08:55,765 | auto-learn error
2025-11-17 09:08:55,766 | 10.242.233.111 - - [17/Nov/2025 09:08:55] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 07:17:41,345 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 07:17:41,563 | Use pytorch device_name: cpu
2025-11-17 07:17:41,563 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 07:17:46,730 | [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3125
 * Running on http://10.60.82.45:3125
2025-11-17 07:17:46,730 | [33mPress CTRL+C to quit[0m
2025-11-17 07:17:46,732 |  * Restarting with stat
2025-11-17 07:18:09,355 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 07:18:09,501 | Use pytorch device_name: cpu
2025-11-17 07:18:09,501 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 07:18:14,259 |  * Debugger is active!
2025-11-17 07:18:14,274 |  * Debugger PIN: 136-249-302
2025-11-17 07:18:29,878 | Traceback (most recent call last):
  File "D:\Python Jupiter\Lib\site-packages\werkzeug\wrappers\request.py", line 611, in get_json
    rv = self.json_module.loads(data)
  File "D:\Python Jupiter\Lib\site-packages\flask\json\provider.py", line 188, in loads
    return json.loads(s, **kwargs)
           ~~~~~~~~~~^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\json\__init__.py", line 341, in loads
    s = s.decode(detect_encoding(s), 'surrogatepass')
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe0 in position 37: invalid continuation byte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 151, in chat
    data = request.json or {}
           ^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\werkzeug\wrappers\request.py", line 560, in json
    return self.get_json()
           ~~~~~~~~~~~~~^^
  File "D:\Python Jupiter\Lib\site-packages\werkzeug\wrappers\request.py", line 620, in get_json
    rv = self.on_json_loading_failed(e)
  File "D:\Python Jupiter\Lib\site-packages\flask\wrappers.py", line 130, in on_json_loading_failed
    return super().on_json_loading_failed(e)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
  File "D:\Python Jupiter\Lib\site-packages\werkzeug\wrappers\request.py", line 645, in on_json_loading_failed
    raise BadRequest(f"Failed to decode JSON object: {e}")
werkzeug.exceptions.BadRequest: 400 Bad Request: Failed to decode JSON object: 'utf-8' codec can't decode byte 0xe0 in position 37: invalid continuation byte

2025-11-17 07:18:29,879 | 127.0.0.1 - - [17/Nov/2025 07:18:29] "[35m[1mPOST /api/chat HTTP/1.1[0m" 500 -
2025-11-17 07:19:42,355 | Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 152, in chat
    user_message = (data.get("message") or "").trim()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'trim'. Did you mean: 'strip'?

2025-11-17 07:19:42,356 | 127.0.0.1 - - [17/Nov/2025 07:19:42] "[35m[1mPOST /api/chat HTTP/1.1[0m" 500 -
2025-11-17 07:20:03,611 | Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 152, in chat
    user_message = (data.get("message") or "").trim()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'str' object has no attribute 'trim'. Did you mean: 'strip'?

2025-11-17 07:20:03,611 | 127.0.0.1 - - [17/Nov/2025 07:20:03] "[35m[1mPOST /api/chat HTTP/1.1[0m" 500 -
2025-11-17 07:22:02,812 |  * Detected change in 'D:\\Android\\Projects\\Nihongo\\backend AI\\nihongo.py', reloading
2025-11-17 07:22:05,417 |  * Restarting with stat
2025-11-17 07:22:29,674 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 07:22:29,856 | Use pytorch device_name: cpu
2025-11-17 07:22:29,856 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 07:22:38,816 |  * Debugger is active!
2025-11-17 07:22:38,820 |  * Debugger PIN: 136-249-302
2025-11-17 07:22:39,037 | AFC is enabled with max remote calls: 10.
2025-11-17 07:23:11,568 | HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-11-17 07:23:11,794 | auto-learn error
2025-11-17 07:23:11,796 | 127.0.0.1 - - [17/Nov/2025 07:23:11] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 07:38:04,749 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 07:38:04,858 | Use pytorch device_name: cpu
2025-11-17 07:38:04,858 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 07:38:16,641 | [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3125
 * Running on http://10.60.82.45:3125
2025-11-17 07:38:16,642 | [33mPress CTRL+C to quit[0m
2025-11-17 07:38:16,643 |  * Restarting with stat
2025-11-17 07:38:31,884 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 07:38:32,003 | Use pytorch device_name: cpu
2025-11-17 07:38:32,003 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 07:38:40,112 |  * Debugger is active!
2025-11-17 07:38:40,115 |  * Debugger PIN: 136-249-302
2025-11-17 07:48:45,168 | AFC is enabled with max remote calls: 10.
2025-11-17 07:48:49,696 | HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-11-17 07:48:49,768 | auto-learn error
2025-11-17 07:48:49,770 | 127.0.0.1 - - [17/Nov/2025 07:48:49] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 07:53:40,315 |  * Detected change in 'D:\\Android\\Projects\\Nihongo\\backend AI\\nihongo.py', reloading
2025-11-17 07:53:40,489 |  * Detected change in 'D:\\Android\\Projects\\Nihongo\\backend AI\\nihongo.py', reloading
2025-11-17 07:53:46,370 |  * Restarting with stat
2025-11-17 07:53:46,779 |  * Restarting with stat
2025-11-17 07:54:09,308 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 07:54:09,418 | Use pytorch device_name: cpu
2025-11-17 07:54:09,418 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 07:54:09,779 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 07:54:09,967 | Use pytorch device_name: cpu
2025-11-17 07:54:09,967 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 07:54:14,119 |  * Debugger is active!
2025-11-17 07:54:14,122 |  * Debugger PIN: 136-249-302
2025-11-17 07:54:14,454 |  * Debugger is active!
2025-11-17 07:54:14,459 |  * Debugger PIN: 136-249-302
2025-11-17 07:56:50,398 |  * Detected change in 'D:\\Android\\Projects\\Nihongo\\backend AI\\nihongo.py', reloading
2025-11-17 07:56:51,007 |  * Detected change in 'D:\\Android\\Projects\\Nihongo\\backend AI\\nihongo.py', reloading
2025-11-17 07:56:56,759 |  * Restarting with stat
2025-11-17 07:56:57,072 |  * Restarting with stat
2025-11-17 07:57:17,810 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 07:57:17,940 | Use pytorch device_name: cpu
2025-11-17 07:57:17,940 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 07:57:22,735 |  * Debugger is active!
2025-11-17 07:57:22,738 |  * Debugger PIN: 136-249-302
2025-11-17 07:57:31,965 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 07:57:33,967 | Use pytorch device_name: cpu
2025-11-17 07:57:33,967 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 07:57:39,699 | [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3125
 * Running on http://10.60.82.45:3125
2025-11-17 07:57:39,699 | [33mPress CTRL+C to quit[0m
2025-11-17 07:57:39,701 |  * Restarting with stat
2025-11-17 07:57:55,885 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 07:57:55,985 | Use pytorch device_name: cpu
2025-11-17 07:57:55,986 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 07:58:01,380 |  * Debugger is active!
2025-11-17 07:58:01,403 |  * Debugger PIN: 136-249-302
2025-11-17 08:05:22,405 | Traceback (most recent call last):
  File "D:\Python Jupiter\Lib\site-packages\werkzeug\wrappers\request.py", line 611, in get_json
    rv = self.json_module.loads(data)
  File "D:\Python Jupiter\Lib\site-packages\flask\json\provider.py", line 188, in loads
    return json.loads(s, **kwargs)
           ~~~~~~~~~~^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\json\__init__.py", line 341, in loads
    s = s.decode(detect_encoding(s), 'surrogatepass')
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe0 in position 55: invalid continuation byte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 151, in chat
    data = request.json or {}
           ^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\werkzeug\wrappers\request.py", line 560, in json
    return self.get_json()
           ~~~~~~~~~~~~~^^
  File "D:\Python Jupiter\Lib\site-packages\werkzeug\wrappers\request.py", line 620, in get_json
    rv = self.on_json_loading_failed(e)
  File "D:\Python Jupiter\Lib\site-packages\flask\wrappers.py", line 130, in on_json_loading_failed
    return super().on_json_loading_failed(e)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
  File "D:\Python Jupiter\Lib\site-packages\werkzeug\wrappers\request.py", line 645, in on_json_loading_failed
    raise BadRequest(f"Failed to decode JSON object: {e}")
werkzeug.exceptions.BadRequest: 400 Bad Request: Failed to decode JSON object: 'utf-8' codec can't decode byte 0xe0 in position 55: invalid continuation byte

2025-11-17 08:05:22,406 | 10.60.82.45 - - [17/Nov/2025 08:05:22] "[35m[1mPOST /api/chat HTTP/1.1[0m" 500 -
2025-11-17 08:07:09,653 | Traceback (most recent call last):
  File "D:\Python Jupiter\Lib\site-packages\werkzeug\wrappers\request.py", line 611, in get_json
    rv = self.json_module.loads(data)
  File "D:\Python Jupiter\Lib\site-packages\flask\json\provider.py", line 188, in loads
    return json.loads(s, **kwargs)
           ~~~~~~~~~~^^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\json\__init__.py", line 341, in loads
    s = s.decode(detect_encoding(s), 'surrogatepass')
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe0 in position 55: invalid continuation byte

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\Android\Projects\Nihongo\backend AI\nihongo.py", line 151, in chat
    data = request.json or {}
           ^^^^^^^^^^^^
  File "D:\Python Jupiter\Lib\site-packages\werkzeug\wrappers\request.py", line 560, in json
    return self.get_json()
           ~~~~~~~~~~~~~^^
  File "D:\Python Jupiter\Lib\site-packages\werkzeug\wrappers\request.py", line 620, in get_json
    rv = self.on_json_loading_failed(e)
  File "D:\Python Jupiter\Lib\site-packages\flask\wrappers.py", line 130, in on_json_loading_failed
    return super().on_json_loading_failed(e)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
  File "D:\Python Jupiter\Lib\site-packages\werkzeug\wrappers\request.py", line 645, in on_json_loading_failed
    raise BadRequest(f"Failed to decode JSON object: {e}")
werkzeug.exceptions.BadRequest: 400 Bad Request: Failed to decode JSON object: 'utf-8' codec can't decode byte 0xe0 in position 55: invalid continuation byte

2025-11-17 08:07:09,654 | 10.60.82.45 - - [17/Nov/2025 08:07:09] "[35m[1mPOST /api/chat HTTP/1.1[0m" 500 -
2025-11-17 08:07:35,874 | AFC is enabled with max remote calls: 10.
2025-11-17 08:07:37,921 | HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-11-17 08:07:38,016 | auto-learn error
2025-11-17 08:07:38,016 | 10.60.82.45 - - [17/Nov/2025 08:07:38] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 08:07:58,198 | 10.60.82.45 - - [17/Nov/2025 08:07:58] "[31m[1mGET /api/chat HTTP/1.1[0m" 405 -
2025-11-17 08:08:00,164 | 10.60.82.45 - - [17/Nov/2025 08:08:00] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-11-17 22:04:08,020 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 22:04:08,392 | Use pytorch device_name: cpu
2025-11-17 22:04:08,392 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 22:04:23,725 | [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3125
 * Running on http://192.168.2.62:3125
2025-11-17 22:04:23,725 | [33mPress CTRL+C to quit[0m
2025-11-17 22:04:23,728 |  * Restarting with stat
2025-11-17 22:04:48,201 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 22:04:48,333 | Use pytorch device_name: cpu
2025-11-17 22:04:48,333 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 22:04:52,524 |  * Debugger is active!
2025-11-17 22:04:52,528 |  * Debugger PIN: 136-249-302
2025-11-17 22:08:49,213 | 127.0.0.1 - - [17/Nov/2025 22:08:49] "[33mGET / HTTP/1.1[0m" 404 -
2025-11-17 22:08:49,923 | 127.0.0.1 - - [17/Nov/2025 22:08:49] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-11-17 22:11:20,650 | AFC is enabled with max remote calls: 10.
2025-11-17 22:11:22,252 | HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-11-17 22:11:22,340 | auto-learn error
2025-11-17 22:11:22,341 | 127.0.0.1 - - [17/Nov/2025 22:11:22] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 22:11:37,816 | AFC is enabled with max remote calls: 10.
2025-11-17 22:11:40,060 | AFC is enabled with max remote calls: 10.
2025-11-17 22:11:40,261 | HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-11-17 22:11:40,338 | auto-learn error
2025-11-17 22:11:40,339 | 127.0.0.1 - - [17/Nov/2025 22:11:40] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 22:11:41,190 | HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-11-17 22:11:41,267 | auto-learn error
2025-11-17 22:11:41,268 | 127.0.0.1 - - [17/Nov/2025 22:11:41] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 22:11:41,415 | AFC is enabled with max remote calls: 10.
2025-11-17 22:11:43,219 | HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-11-17 22:11:43,280 | auto-learn error
2025-11-17 22:11:43,281 | 127.0.0.1 - - [17/Nov/2025 22:11:43] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 22:11:44,205 | AFC is enabled with max remote calls: 10.
2025-11-17 22:11:46,072 | HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-11-17 22:11:46,121 | auto-learn error
2025-11-17 22:11:46,122 | 127.0.0.1 - - [17/Nov/2025 22:11:46] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 22:11:47,053 | AFC is enabled with max remote calls: 10.
2025-11-17 22:11:49,034 | HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-11-17 22:11:49,096 | auto-learn error
2025-11-17 22:11:49,097 | 127.0.0.1 - - [17/Nov/2025 22:11:49] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 22:11:50,030 | AFC is enabled with max remote calls: 10.
2025-11-17 22:11:51,780 | HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent "HTTP/1.1 200 OK"
2025-11-17 22:11:51,897 | auto-learn error
2025-11-17 22:11:51,899 | 127.0.0.1 - - [17/Nov/2025 22:11:51] "POST /api/chat HTTP/1.1" 200 -
2025-11-17 23:13:49,107 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 23:13:49,420 | Use pytorch device_name: cpu
2025-11-17 23:13:49,420 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 23:13:53,260 | [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:3125
 * Running on http://192.168.2.62:3125
2025-11-17 23:13:53,260 | [33mPress CTRL+C to quit[0m
2025-11-17 23:13:53,262 |  * Restarting with stat
2025-11-17 23:14:16,589 | Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.
2025-11-17 23:14:16,690 | Use pytorch device_name: cpu
2025-11-17 23:14:16,690 | Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-11-17 23:14:20,645 |  * Debugger is active!
2025-11-17 23:14:20,650 |  * Debugger PIN: 136-249-302
